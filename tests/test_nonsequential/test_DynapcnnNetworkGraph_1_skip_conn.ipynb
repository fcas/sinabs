{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sinabs.from_torch import from_model\n",
    "from sinabs.backend.dynapcnn import DynapcnnNetwork, DynapcnnNetworkGraph\n",
    "import sinabs as snb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb47e7a8c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "input_shape = (channels, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Module (pure Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.con1 = nn.Conv2d(1, 20, 5, 1, bias=False)\n",
    "        self.rel1 = nn.ReLU()\n",
    "        self.pool1 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(20, 32, 5, 1, bias=False)\n",
    "        self.rel2 = nn.ReLU()\n",
    "        self.pool2 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 128, 3, 1, bias=False)\n",
    "        self.rel3 = nn.ReLU()\n",
    "        self.pool3 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(128, 500, bias=False)\n",
    "        self.rel4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500, 10, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        con1_out = self.con1(x)\n",
    "        rel1_out = self.rel1(con1_out)\n",
    "        pool1_out = self.pool1(rel1_out)\n",
    "\n",
    "        conv2_out = self.conv2(pool1_out)\n",
    "        rel2_out = self.rel2(conv2_out)\n",
    "        pool2_out = self.pool2(rel2_out)\n",
    "\n",
    "        conv3_out = self.conv3(pool2_out + rel1_out)\n",
    "        rel3_out = self.rel3(conv3_out)\n",
    "        pool3_out = self.pool3(rel3_out)\n",
    "\n",
    "        flat_out = self.flat(pool3_out)\n",
    "        \n",
    "        fc1_out = self.fc1(flat_out)\n",
    "        rel4_out = self.rel4(fc1_out)\n",
    "        fc2_out = self.fc2(rel4_out)\n",
    "\n",
    "        return fc2_out\n",
    "\n",
    "rescnn = ResCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinabs Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinabs_model = from_model(rescnn, add_spiking_output=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResCNN(\n",
      "  (con1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (rel1): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(1.), min_v_mem=Parameter containing:\n",
      "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (rel2): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(1.), min_v_mem=Parameter containing:\n",
      "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (rel3): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(1.), min_v_mem=Parameter containing:\n",
      "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=128, out_features=500, bias=False)\n",
      "  (rel4): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(1.), min_v_mem=Parameter containing:\n",
      "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=False)\n",
      "  (spike_output): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(1.), min_v_mem=Parameter containing:\n",
      "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sinabs_model.spiking_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResCNN(\n",
      "  (con1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (rel1): ReLU()\n",
      "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (rel2): ReLU()\n",
      "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (rel3): ReLU()\n",
      "  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=128, out_features=500, bias=False)\n",
      "  (rel4): ReLU()\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sinabs_model.analog_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DynapCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (24) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hw_model \u001b[38;5;241m=\u001b[39m DynapcnnNetworkGraph(\n\u001b[1;32m      2\u001b[0m     sinabs_model,\n\u001b[1;32m      3\u001b[0m     discretize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39minput_shape\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/github/sinabs/sinabs/backend/dynapcnn/dynapcnn_network_graph.py:68\u001b[0m, in \u001b[0;36mDynapcnnNetworkGraph.__init__\u001b[0;34m(self, snn, input_shape, dvs_input, discretize)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     66\u001b[0m dvs_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m                                           \u001b[38;5;66;03m# TODO for now the graph part is not taking into consideration this.\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_tracer \u001b[38;5;241m=\u001b[39m GraphTracer(                            \u001b[38;5;66;03m# computational graph from original PyTorch module.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     snn\u001b[38;5;241m.\u001b[39manalog_model, \n\u001b[1;32m     70\u001b[0m     torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39minput_shape))                          \u001b[38;5;66;03m# torch.jit needs the batch dimension.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m convert_model_to_layer_list(                  \u001b[38;5;66;03m# convert models  to sequential.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     model\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mspiking_model, ignore\u001b[38;5;241m=\u001b[39mDEFAULT_IGNORED_LAYER_TYPES\n\u001b[1;32m     77\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/github/sinabs/sinabs/backend/dynapcnn/graph_tracer.py:14\u001b[0m, in \u001b[0;36mGraphTracer.__init__\u001b[0;34m(self, model, dummy_input)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: Union[nn\u001b[38;5;241m.\u001b[39mSequential, nn\u001b[38;5;241m.\u001b[39mModule], dummy_input: np\u001b[38;5;241m.\u001b[39marray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" .\"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     trace \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mtrace(model, dummy_input)\n\u001b[1;32m     15\u001b[0m     _ \u001b[38;5;241m=\u001b[39m trace(dummy_input)\n\u001b[1;32m     16\u001b[0m     __ \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(trace)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/jit/_trace.py:806\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    807\u001b[0m         func,\n\u001b[1;32m    808\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    810\u001b[0m         check_trace,\n\u001b[1;32m    811\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    812\u001b[0m         check_tolerance,\n\u001b[1;32m    813\u001b[0m         strict,\n\u001b[1;32m    814\u001b[0m         _force_outplace,\n\u001b[1;32m    815\u001b[0m         _module_class,\n\u001b[1;32m    816\u001b[0m         example_inputs_is_kwarg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(example_kwarg_inputs, \u001b[38;5;28mdict\u001b[39m),\n\u001b[1;32m    817\u001b[0m         _store_inputs\u001b[38;5;241m=\u001b[39m_store_inputs,\n\u001b[1;32m    818\u001b[0m     )\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    823\u001b[0m ):\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/jit/_trace.py:1074\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1073\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1074\u001b[0m     module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_create_method_from_trace(\n\u001b[1;32m   1075\u001b[0m         method_name,\n\u001b[1;32m   1076\u001b[0m         func,\n\u001b[1;32m   1077\u001b[0m         example_inputs,\n\u001b[1;32m   1078\u001b[0m         var_lookup_fn,\n\u001b[1;32m   1079\u001b[0m         strict,\n\u001b[1;32m   1080\u001b[0m         _force_outplace,\n\u001b[1;32m   1081\u001b[0m         argument_names,\n\u001b[1;32m   1082\u001b[0m         _store_inputs,\n\u001b[1;32m   1083\u001b[0m     )\n\u001b[1;32m   1085\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1501\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mResCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m rel2_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel2(conv2_out)\n\u001b[1;32m     31\u001b[0m pool2_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(rel2_out)\n\u001b[0;32m---> 33\u001b[0m conv3_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(pool2_out \u001b[38;5;241m+\u001b[39m rel1_out)\n\u001b[1;32m     34\u001b[0m rel3_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel3(conv3_out)\n\u001b[1;32m     35\u001b[0m pool3_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool3(rel3_out)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (24) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "hw_model = DynapcnnNetworkGraph(\n",
    "    sinabs_model,\n",
    "    discretize=True,\n",
    "    input_shape=input_shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "1 IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "2 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "3 Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "4 IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "5 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "6 Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "7 IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "8 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "9 Linear(in_features=128, out_features=500, bias=False)\n",
      "10 IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n",
      "11 Linear(in_features=500, out_features=10, bias=False)\n",
      "12 IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=1, num_timesteps=-1)\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(hw_model.layers):\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(1, 2)\n",
      "(2, 3)\n",
      "(3, 4)\n",
      "(4, 5)\n",
      "(5, 6)\n",
      "(6, 7)\n",
      "(7, 8)\n",
      "(8, 9)\n",
      "(9, 10)\n",
      "(10, 11)\n",
      "(11, 12)\n"
     ]
    }
   ],
   "source": [
    "for edge in hw_model.sinabs_edges:\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network is valid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DynapcnnNetworkGraph()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_model.to(device=\"speck2edevkit:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer index: 0\n",
      "layer modules: DynapcnnLayer(\n",
      "  (conv_layer): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (spk_layer): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(635.), min_v_mem=Parameter containing:\n",
      "  tensor(-635.), batch_size=1, num_timesteps=-1)\n",
      "  (pool_layer): SumPool2d(norm_type=1, kernel_size=(2, 2), stride=None, ceil_mode=False)\n",
      ")\n",
      "layer destinations: [1]\n",
      "assigned core: 0\n",
      "\n",
      "layer index: 1\n",
      "layer modules: DynapcnnLayer(\n",
      "  (conv_layer): Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (spk_layer): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(11361.), min_v_mem=Parameter containing:\n",
      "  tensor(-11361.), batch_size=1, num_timesteps=-1)\n",
      "  (pool_layer): SumPool2d(norm_type=1, kernel_size=(2, 2), stride=None, ceil_mode=False)\n",
      ")\n",
      "layer destinations: [2]\n",
      "assigned core: 3\n",
      "\n",
      "layer index: 2\n",
      "layer modules: DynapcnnLayer(\n",
      "  (conv_layer): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (spk_layer): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(8621.), min_v_mem=Parameter containing:\n",
      "  tensor(-8621.), batch_size=1, num_timesteps=-1)\n",
      "  (pool_layer): SumPool2d(norm_type=1, kernel_size=(2, 2), stride=None, ceil_mode=False)\n",
      ")\n",
      "layer destinations: [3]\n",
      "assigned core: 5\n",
      "\n",
      "layer index: 3\n",
      "layer modules: DynapcnnLayer(\n",
      "  (conv_layer): Conv2d(128, 500, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (spk_layer): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(5747.), min_v_mem=Parameter containing:\n",
      "  tensor(-5747.), batch_size=1, num_timesteps=-1)\n",
      ")\n",
      "layer destinations: [4]\n",
      "assigned core: 6\n",
      "\n",
      "layer index: 4\n",
      "layer modules: DynapcnnLayer(\n",
      "  (conv_layer): Conv2d(500, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (spk_layer): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "  tensor(2841.), min_v_mem=Parameter containing:\n",
      "  tensor(-2841.), batch_size=1, num_timesteps=-1)\n",
      ")\n",
      "layer destinations: []\n",
      "assigned core: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hw_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speck-rescnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
