{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union\n",
    "import re, copy\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f780f760c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "input_dummy = torch.randn((1, channels, height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTracer():\n",
    "    def __init__(self, model: Union[nn.Sequential, nn.Module], dummy_input: np.array) -> None:\n",
    "        \"\"\" .\"\"\"\n",
    "\n",
    "        trace = torch.jit.trace(model, dummy_input)\n",
    "        _ = trace(dummy_input)\n",
    "        __ = copy.deepcopy(trace)\n",
    "\n",
    "        self.graph = __.graph\n",
    "\n",
    "        self.modules_map, self.name_2_indx_map  = self.get_named_modules(model)\n",
    "        self.forward_edges                      = self.get_foward_edges()\n",
    "        self.ATens                              = self.get_ATen_operations()\n",
    "        self.edges_list                         = self.get_graph_edges()\n",
    "\n",
    "    def from_name_2_indx(self, name):\n",
    "        if name in self.name_2_indx_map:\n",
    "            return self.name_2_indx_map[name]\n",
    "        else:\n",
    "            last_indx = None\n",
    "            for _name, indx in self.name_2_indx_map.items():\n",
    "                last_indx = indx\n",
    "            self.name_2_indx_map[name] = last_indx+1\n",
    "            return self.name_2_indx_map[name]\n",
    "\n",
    "    def get_named_modules(self, module: nn.Module):\n",
    "        \"\"\" .\"\"\"\n",
    "        modules_map = {}\n",
    "        name_2_indx_map = {}\n",
    "        indx = 0\n",
    "        for name, mod in module.named_modules():\n",
    "            if name:\n",
    "                modules_map[indx] = mod\n",
    "                name_2_indx_map[name] = indx\n",
    "                indx += 1\n",
    "        return modules_map, name_2_indx_map\n",
    "    \n",
    "    def get_foward_edges(self):\n",
    "        \"\"\" .\"\"\"\n",
    "        forward_edges = {}\n",
    "        for node in self.graph.nodes():\n",
    "            node = str(node)\n",
    "            regex = re.compile(r'%(.*?) :.*prim::CallMethod\\[name=\"forward\"\\]\\(%(.*?), %(.*?)\\)')\n",
    "            match = regex.search(node)\n",
    "            if match:\n",
    "                source = match.group(3).replace('_', '')\n",
    "                target = match.group(2).replace('_', '')\n",
    "                result = match.group(1).replace('_', '')\n",
    "                forward_edges[self.from_name_2_indx(result)] = (self.from_name_2_indx(source), self.from_name_2_indx(target))\n",
    "                \n",
    "        return forward_edges\n",
    "\n",
    "    def get_graph_edges(self):\n",
    "        \"\"\" .\"\"\"\n",
    "        edges = []\n",
    "        last_result = None\n",
    "\n",
    "        for result_node, forward_edge in self.forward_edges.items():\n",
    "            src = forward_edge[0]\n",
    "            trg = forward_edge[1]\n",
    "\n",
    "            if not last_result:\n",
    "                last_result = result_node\n",
    "                edges.append(('input', trg))\n",
    "            elif src == last_result:\n",
    "                edges.append((edges[-1][1], trg))\n",
    "                last_result = result_node\n",
    "            else:\n",
    "                scr1, scr2 = self.get_ATen_operands(src)\n",
    "                edges.append((scr1, trg))\n",
    "                edges.append((scr2, trg))\n",
    "                last_result = result_node\n",
    "    \n",
    "        edges.append((edges[-1][1], 'output'))\n",
    "\n",
    "        return edges[1:-1]\n",
    "    \n",
    "    def get_ATen_operands(self, node):\n",
    "        \"\"\" .\"\"\"\n",
    "        if node in self.ATens:\n",
    "            src1 = self.ATens[node]['args'][1]\n",
    "            src2 = self.ATens[node]['args'][0]\n",
    "            return self.forward_edges[src1][1], self.forward_edges[src2][1]\n",
    "        else:\n",
    "            # throw error\n",
    "            return None, None\n",
    "        \n",
    "    def get_ATen_operations(self):\n",
    "        \"\"\" ATen is PyTorch's tensor library backend, which provides a set of operations that operate on \n",
    "        tensors directly. These include arithmetic operations (add, mul, etc.), mathematical \n",
    "        functions (sin, cos, etc.), and tensor manipulation operations (view, reshape, etc.).\"\"\"\n",
    "        ATens = {}\n",
    "        for node in self.graph.nodes():\n",
    "            node = str(node)\n",
    "            regex = re.compile(r'%(.*?) :.*aten::(.*?)\\(%(.*?), %(.*?), %(.*?)\\)')\n",
    "\n",
    "            match = regex.search(node)\n",
    "\n",
    "            if match:\n",
    "                result_node = match.group(1)\n",
    "                operation = match.group(2)\n",
    "                operator1 = self.from_name_2_indx(match.group(3))\n",
    "                operator2 = self.from_name_2_indx(match.group(4))\n",
    "                const_operator = match.group(5)\n",
    "                ATens[result_node] = {'op': operation, 'args': (operator1, operator2, const_operator)}\n",
    "        return ATens\n",
    "    \n",
    "    def remove_ignored_nodes(self, default_ignored_nodes):\n",
    "        \"\"\" Recreates the edges list based on layers that 'DynapcnnNetwork' will ignore. This\n",
    "        is done by setting the source (target) node of an edge where the source (target) node\n",
    "        will be dropped as the node that originally targeted this node to be dropped.\n",
    "        \"\"\"\n",
    "        edges = copy.deepcopy(self.edges_list)\n",
    "        parsed_edges = []\n",
    "        removed_nodes = []\n",
    "\n",
    "        # removing ignored nodes from edges.\n",
    "        for edge_idx in range(len(edges)):\n",
    "            _src = edges[edge_idx][0]\n",
    "            _trg = edges[edge_idx][1]\n",
    "\n",
    "            if isinstance(self.modules_map[_src], default_ignored_nodes):\n",
    "                removed_nodes.append(_src)\n",
    "                # all edges where node '_src' is target change it to node '_trg' as their target.\n",
    "                for edge in edges:\n",
    "                    if edge[1] == _src:\n",
    "                        new_edge = (edge[0], _trg)\n",
    "            elif isinstance(self.modules_map[_trg], default_ignored_nodes):\n",
    "                removed_nodes.append(_trg)\n",
    "                # all edges where node '_trg' is source change it to node '_src' as their source.\n",
    "                for edge in edges:\n",
    "                    if edge[0] == _trg:\n",
    "                        new_edge = (_src, edge[1])\n",
    "            else:\n",
    "                new_edge = (_src, _trg)\n",
    "            \n",
    "            if new_edge not in parsed_edges:\n",
    "                parsed_edges.append(new_edge)\n",
    "\n",
    "        removed_nodes = list(set(removed_nodes))\n",
    "\n",
    "        # remapping nodes indexes.\n",
    "        remapped_nodes = {}\n",
    "        for node_indx, __ in self.modules_map.items():\n",
    "            _ = [x for x in removed_nodes if node_indx > x]\n",
    "            remapped_nodes[node_indx] = node_indx - len(_)\n",
    "            \n",
    "        for x in removed_nodes:\n",
    "            del remapped_nodes[x]\n",
    "\n",
    "        # remapping nodes names in parsed edges.\n",
    "        remapped_edges = []\n",
    "        for edge in parsed_edges:\n",
    "            remapped_edges.append((remapped_nodes[edge[0]], remapped_nodes[edge[1]]))\n",
    "\n",
    "        return remapped_edges\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_graph(edges_list):\n",
    "        \"\"\" .\"\"\"\n",
    "        G = nx.DiGraph(edges_list)\n",
    "        layout = nx.spring_layout(G)\n",
    "        nx.draw(G, pos = layout, with_labels=True, node_size=800)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.con1 = nn.Conv2d(1, 20, 5, 1, bias=False)\n",
    "        self.rel1 = nn.ReLU()\n",
    "        self.pool1 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(20, 32, 5, 1, bias=False)\n",
    "        self.rel2 = nn.ReLU()\n",
    "        self.pool2 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 128, 3, 1, bias=False)\n",
    "        self.rel3 = nn.ReLU()\n",
    "        self.pool3 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(128, 500, bias=False)\n",
    "        self.rel4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500, 10, bias=False)\n",
    "\n",
    "        self.residual_projection = nn.Conv2d(20, 32, 1, 6, bias=False)  # from self.con1 to self.con3.\n",
    "        self.residual_projection.weight.requires_grad = False           # no training of parameters.\n",
    "        self.residual_projection.weight.data.fill_(1)                   # compute the identity.\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        con1_out = self.con1(x)\n",
    "        rel1_out = self.rel1(con1_out)\n",
    "        pool1_out = self.pool1(rel1_out)\n",
    "\n",
    "        residual = self.residual_projection(rel1_out)\n",
    "\n",
    "        conv2_out = self.conv2(pool1_out)\n",
    "        rel2_out = self.rel2(conv2_out)\n",
    "        pool2_out = self.pool2(rel2_out)\n",
    "\n",
    "        conv3_out = self.conv3(pool2_out + residual)\n",
    "        rel3_out = self.rel3(conv3_out)\n",
    "        pool3_out = self.pool3(rel3_out)\n",
    "\n",
    "        flat_out = self.flat(pool3_out)\n",
    "        \n",
    "        fc1_out = self.fc1(flat_out)\n",
    "        rel4_out = self.rel4(fc1_out)\n",
    "        fc2_out = self.fc2(rel4_out)\n",
    "\n",
    "        return fc2_out\n",
    "\n",
    "ann2 = ANN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1_out = ann2.rel1(ann2.con1(input_dummy))\n",
    "pool1 = ann2.pool1(con1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "con2_out = ann2.rel2(ann2.conv2(pool1))\n",
    "pool2 = ann2.pool2(con2_out)\n",
    "\n",
    "print(pool2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "residual = ann2.residual_projection(con1_out)\n",
    "\n",
    "print(residual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtracer2 = GraphTracer(ann2, input_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "1 ReLU()\n",
      "2 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "3 Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "4 ReLU()\n",
      "5 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "6 Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "7 ReLU()\n",
      "8 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "9 Flatten(start_dim=1, end_dim=-1)\n",
      "10 Linear(in_features=128, out_features=500, bias=False)\n",
      "11 ReLU()\n",
      "12 Linear(in_features=500, out_features=10, bias=False)\n",
      "13 Conv2d(20, 32, kernel_size=(1, 1), stride=(6, 6), bias=False)\n"
     ]
    }
   ],
   "source": [
    "for name, mod in gtracer2.modules_map.items():\n",
    "    print(name, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(1, 2)\n",
      "(None, 18)\n",
      "(None, 18)\n",
      "(None, 3)\n",
      "(None, 3)\n",
      "(3, 4)\n",
      "(4, 5)\n",
      "(None, 6)\n",
      "(None, 6)\n",
      "(6, 7)\n",
      "(7, 8)\n",
      "(8, 9)\n",
      "(9, 10)\n",
      "(10, 11)\n",
      "(11, 12)\n"
     ]
    }
   ],
   "source": [
    "for edge in gtracer2.edges_list:\n",
    "    print(edge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speck-rescnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
