{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tonic.transforms import ToFrame\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from seq_model import SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch_size_pre = 32\n",
    "num_workers = 1\n",
    "epochs_pretrain = 1\n",
    "epochs = 30\n",
    "lr = 1e-3\n",
    "n_time_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  NVIDIA GeForce RTX 3070 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('device: ', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, feature_map_size, dataloader_train, model, loss_fn, optimizer, epochs, test_func, dataloader_test, phase):\n",
    "    epochs_y = []\n",
    "    epochs_x = []\n",
    "    epochs_acc = []\n",
    "    model.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        losses = []\n",
    "        batches = []\n",
    "        batch_count = 0\n",
    "        train_p_bar = tqdm(dataloader_train)\n",
    "\n",
    "        for X, y in train_p_bar:\n",
    "            # reshape the input from [Batch, Time, Channel, Height, Width] into [Batch*Time, Channel, Height, Width]\n",
    "            X = X.reshape(-1, feature_map_size[2], feature_map_size[0], feature_map_size[1]).to(dtype=torch.float, device=device)\n",
    "            y = y.to(dtype=torch.long, device=device)\n",
    "\n",
    "            # forward\n",
    "            pred = model(X)\n",
    "\n",
    "            # reshape the output from [Batch*Time,num_classes] into [Batch, Time, num_classes]\n",
    "            pred = pred.reshape(batch_size, n_time_steps, -1)\n",
    "\n",
    "            # accumulate all time-steps output for final prediction\n",
    "            pred = pred.sum(dim = 1)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # gradient update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # detach the neuron states and activations from current computation graph(necessary)\n",
    "            model.detach_neuron_states()\n",
    "\n",
    "            train_p_bar.set_description(f\"{phase} - Epoch {e} - BPTT Training Loss: {round(loss.item(), 4)}\")\n",
    "\n",
    "            batch_count += 1\n",
    "            losses.append(loss.item())\n",
    "            batches.append(batch_count)\n",
    "\n",
    "        epochs_y.append(losses)\n",
    "        epochs_x.append(batches)\n",
    "\n",
    "        acc = test_func(feature_map_size, dataloader_test, model)\n",
    "        print(f'{phase} - Epoch {e} accuracy: {acc}')\n",
    "        epochs_acc.append(acc)\n",
    "\n",
    "    return epochs_x, epochs_y, epochs_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(feature_map_size, dataloader, model):\n",
    "    correct_predictions = []\n",
    "    with torch.no_grad():\n",
    "        test_p_bar = tqdm(dataloader)\n",
    "        for X, y in test_p_bar:\n",
    "            # reshape the input from [Batch, Time, Channel, Height, Width] into [Batch*Time, Channel, Height, Width]\n",
    "            X = X.reshape(-1, feature_map_size[2], feature_map_size[0], feature_map_size[1]).to(dtype=torch.float, device=device)\n",
    "            y = y.to(dtype=torch.long, device=device)\n",
    "\n",
    "            # forward\n",
    "            output = model(X)\n",
    "\n",
    "            # reshape the output from [Batch*Time,num_classes] into [Batch, Time, num_classes]\n",
    "            output = output.reshape(batch_size, n_time_steps, -1)\n",
    "\n",
    "            # accumulate all time-steps output for final prediction\n",
    "            output = output.sum(dim=1)\n",
    "\n",
    "            # calculate accuracy\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            # compute the total correct predictions\n",
    "            correct_predictions.append(pred.eq(y.view_as(pred)))\n",
    "\n",
    "            test_p_bar.set_description(f\"Testing Model...\")\n",
    "    \n",
    "    correct_predictions = torch.cat(correct_predictions)\n",
    "    return correct_predictions.sum().item()/(len(correct_predictions))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pre-training data. Dataset used to pre-train the network such that its parameters are set within a \"good\" region of the parameters space (i.e., hopefully training on a \"simpler\" dataset sets the wheights to values that improve the training on a harder dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transformed array is in shape [Time-Step, Channel, Height, Width] --> (50, 2, 34, 34)\n"
     ]
    }
   ],
   "source": [
    "from tonic.datasets.nmnist import NMNIST\n",
    "\n",
    "root_dir = \"../NMNIST\"\n",
    "_ = NMNIST(save_to=root_dir, train=True)\n",
    "_ = NMNIST(save_to=root_dir, train=False)\n",
    "\n",
    "to_raster = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=n_time_steps)\n",
    "\n",
    "snn_train_dataset_pre = NMNIST(save_to=root_dir, train=True, transform=to_raster)\n",
    "snn_test_dataset_pre = NMNIST(save_to=root_dir, train=False, transform=to_raster)\n",
    "\n",
    "sample_data, label = snn_train_dataset_pre[0]\n",
    "print(f\"The transformed array is in shape [Time-Step, Channel, Height, Width] --> {sample_data.shape}\")\n",
    "\n",
    "snn_train_dataloader_pre = DataLoader(snn_train_dataset_pre, batch_size=batch_size_pre, num_workers=num_workers, drop_last=True, shuffle=True)\n",
    "snn_test_dataloader_pre = DataLoader(snn_test_dataset_pre, batch_size=batch_size_pre, num_workers=num_workers, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instantiating model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = SNN(10, 10, batch_size_pre).to(device)\n",
    "snn.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss and optimizer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(snn.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-training the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bfe44485924a4a85b3357e62c24e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_x_pre, epochs_y_pre, epochs_acc_pre = train(\n",
    "    batch_size_pre,\n",
    "    NMNIST.sensor_size, \n",
    "    snn_train_dataloader_pre, \n",
    "    snn, \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    epochs_pretrain, \n",
    "    test, \n",
    "    snn_test_dataloader_pre,\n",
    "    'pre-training'\n",
    "    )\n",
    "\n",
    "snn.export_conv_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = []\n",
    "for y in epochs_y_pre:\n",
    "    y_avg.append(np.mean(y))\n",
    "\n",
    "plt.plot(np.arange(len(epochs_x_pre)), y_avg, marker = '.')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('average loss')\n",
    "plt.ylim(0,)\n",
    "plt.xticks(np.arange(len(epochs_x_pre)))\n",
    "for i, txt in enumerate(y_avg):\n",
    "    if i%2 == 0:\n",
    "        pass\n",
    "    else:\n",
    "        plt.text(i, txt, f'{txt:.2f}', ha='center', va='bottom', color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(epochs_x_pre)), epochs_acc_pre, marker = '.')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('test accuracy')\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(np.arange(len(epochs_x_pre)))\n",
    "for i, txt in enumerate(epochs_acc_pre):\n",
    "    if i%2 == 0:\n",
    "        pass\n",
    "    else:\n",
    "        plt.text(i, txt, f'{txt:.2f}', ha='center', va='bottom', color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Post-training\" loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonic.datasets.dvsgesture import DVSGesture\n",
    "\n",
    "root_dir = \"../DVSGESTURE\"\n",
    "_ = DVSGesture(save_to=root_dir, train=True)\n",
    "_ = DVSGesture(save_to=root_dir, train=False)\n",
    "\n",
    "to_raster = ToFrame(sensor_size=DVSGesture.sensor_size, n_time_bins=n_time_steps)\n",
    "\n",
    "snn_train_dataset = DVSGesture(save_to=root_dir, train=True, transform=to_raster)\n",
    "snn_test_dataset = DVSGesture(save_to=root_dir, train=False, transform=to_raster)\n",
    "\n",
    "sample_data, label = snn_train_dataset[0]\n",
    "print(f\"The transformed array is in shape [Time-Step, Channel, Height, Width] --> {sample_data.shape}\")\n",
    "\n",
    "snn_train_dataloader = DataLoader(snn_train_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=True)\n",
    "snn_test_dataloader = DataLoader(snn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instantiating model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = SNN(11, 810, batch_size).to(device)\n",
    "snn.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading weights from pre-training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.load_conv_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss and optimizer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(snn.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_x_dvs128, epochs_y_dvs128, epochs_acc_dvs128 = train(\n",
    "    batch_size,\n",
    "    DVSGesture.sensor_size, \n",
    "    snn_train_dataloader, \n",
    "    snn, \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    epochs, \n",
    "    test, \n",
    "    snn_test_dataloader,\n",
    "    'post-training'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = []\n",
    "for y in epochs_y_dvs128:\n",
    "    y_avg.append(np.mean(y))\n",
    "\n",
    "plt.plot(np.arange(len(epochs_x_dvs128)), y_avg, marker = '.')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('average loss')\n",
    "plt.ylim(0,)\n",
    "plt.xticks(np.arange(len(epochs_x_dvs128)))\n",
    "for i, txt in enumerate(y_avg):\n",
    "    if i%2 == 0:\n",
    "        pass\n",
    "    else:\n",
    "        plt.text(i, txt, f'{txt:.2f}', ha='center', va='bottom', color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(epochs_x_dvs128)), epochs_acc_dvs128, marker = '.')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('test accuracy')\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(np.arange(len(epochs_x_dvs128)))\n",
    "for i, txt in enumerate(epochs_acc_dvs128):\n",
    "    if i%2 == 0:\n",
    "        pass\n",
    "    else:\n",
    "        plt.text(i, txt, f'{txt:.2f}', ha='center', va='bottom', color = 'k')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speck-rescnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
