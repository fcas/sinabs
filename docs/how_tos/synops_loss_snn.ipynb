{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an SNN with fewer synops\n",
    "Similar as in the previous tutorial, we start by defining a spiking model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sinabs\n",
    "import sinabs.layers as sl\n",
    "\n",
    "class SNN(nn.Sequential):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__(\n",
    "            sl.FlattenTime(),\n",
    "            nn.Conv2d(1, 16, 5, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            sl.SumPool2d(2),\n",
    "            nn.Conv2d(16, 32, 5, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            sl.SumPool2d(2),\n",
    "            nn.Conv2d(32, 120, 4, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(120, 10, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            sl.UnflattenTime(batch_size=batch_size),\n",
    "        )\n",
    "\n",
    "batch_size = 5\n",
    "snn = SNN(batch_size=batch_size)\n",
    "snn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SNNAnalyzer` class tracks different statistics for spiking (such as IAF/LIF) and parameter (such as Conv2d/Linear) layers. The number of synaptic operations is part of the parameter layers. If we attach such an analyser to the model, we'll be able to use layer- or model-wide statistics during training, for optimization or logging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = sinabs.SNNAnalyzer(snn)\n",
    "print(f\"Synops before feeding input: {analyser.get_model_statistics()['synops']}\")\n",
    "\n",
    "rand_input_spikes = (torch.ones((batch_size, 10, 1, 28, 28)) ).float()\n",
    "y_hat = snn(rand_input_spikes)\n",
    "print(f\"Synops after feeding input: {analyser.get_model_statistics()['synops']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can break down the statistics for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser.get_layer_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have can calculate the total synops, we might want to choose a target synops number in order to decrease power consumption. As a rule of thumb we're going to take half of the number of initial synops as constant target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the target number of operations\n",
    "target_synops = (analyser.get_model_statistics()['synops'] / 2).clone()#.detach()\n",
    "\n",
    "optim = torch.optim.Adam(snn.parameters())\n",
    "\n",
    "n_synops = []\n",
    "for epoch in range(10):\n",
    "    sinabs.reset_states(snn)\n",
    "    sinabs.zero_grad(snn)\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    output = snn(rand_input_spikes)\n",
    "    synops = analyser.get_model_statistics()['synops']\n",
    "    synops_loss = (target_synops - synops).square() / target_synops.square()\n",
    "    # print(snn[2].v_mem)\n",
    "    print(target_synops)\n",
    "    print(synops_loss)\n",
    "    synops_loss.backward()\n",
    "    optim.step()\n",
    "    # n_synops.append(synops.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_synops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "caf264bf03997fa53b380c84044763293a7a6f8ebb5555ee5243fd4d1f495be6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
