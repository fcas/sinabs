{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From a CNN model to a DYNAP-CNN DevKit\n",
    "\n",
    "This tutorial explains all steps necessary to convert a torch CNN model to a configuration of the DYNAP-CNN chip. We will first convert the network to a spiking neural network (SNN) and then to a `DynapcnnNetwork` â€“ a model that is compatible with the chip and simulates its behavior. Finally we port the model to a DYNAP-CNN DevKit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Before we start, we will import the libraries necessary to define a torch model, convert it to an SNN and to convert the SNN to a `DynapcnnNetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Suppress warnings (This is only to keep the notebook pretty. You might want to comment the below two lines)\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# - Import statements\n",
    "import torch\n",
    "import samna\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from sinabs.from_torch import from_model\n",
    "from sinabs.backend.dynapcnn import io\n",
    "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
    "from sinabs.backend.dynapcnn.chip_factory import ChipFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN definition\n",
    "\n",
    "First we will define a sequential CNN model.\n",
    "\n",
    "*Note that although non-sequential models are supported by the hardware, this is not yet the case for this library.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Define CNN model\n",
    "\n",
    "ann = nn.Sequential(\n",
    "    nn.Conv2d(1, 20, 5, 1, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    nn.Conv2d(20, 32, 5, 1, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    nn.Conv2d(32, 128, 3, 1, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 500, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 10, bias=False),\n",
    ")\n",
    "\n",
    "# Load pre-trained weights\n",
    "ann.load_state_dict(torch.load(\"../../../examples/mnist_params.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are 5 parameter layers in the above defined model. You will see this come into play later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Spiking CNN\n",
    "\n",
    "We can use the `from_torch` method from SINABS to convert our CNN to a SNN. The returned object contains the original CNN as `analog_model` and the newly generated SNN as `spiking_model`. The `ReLU`s have been converted to `SpikingLayers`. In addition, we have also added a spiking layer at the end. This is for compatibitlity with the chip later on, since the chips can only produce spikes and not  activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (1): IAFSqueeze-module, backend: sinabs\n",
      "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (3): Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (4): IAFSqueeze-module, backend: sinabs\n",
      "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (6): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (7): IAFSqueeze-module, backend: sinabs\n",
      "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (9): Flatten(start_dim=1, end_dim=-1)\n",
      "  (10): Linear(in_features=128, out_features=500, bias=False)\n",
      "  (11): IAFSqueeze-module, backend: sinabs\n",
      "  (12): Linear(in_features=500, out_features=10, bias=False)\n",
      "  (Spiking output): IAFSqueeze-module, backend: sinabs\n",
      ")\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "sinabs_model = from_model(ann, add_spiking_output=True, threshold_low=-1)\n",
    "print(sinabs_model.spiking_model)\n",
    "\n",
    "print(sinabs_model.spiking_model[1].threshold_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DYNAP-CNN compatible network\n",
    "\n",
    "The next step is to convert the SNN to a `DynapcnnNetwork`. This way we can be sure that all functionalities of our network are supported by the hardware and we can simulate the expected hardware output for testing purposes. This object will also generate the configuration objects to set up the chip.\n",
    "\n",
    "We need to tell the chip the dimensions of the input data. This can be done either by specifying an `input_shape` argument in the constructor or including a SINABS `InputLayer` at the beginning of the model.\n",
    "\n",
    "The class will convert the parameters (weights, biases, and thresholds) to discrete values that are supported by DYNAP-CNN. For testing purposes this can be disabled by setting `discretize` to `False`.\n",
    "\n",
    "We can use the `dvs_input` flag to determine whether the chip should process data coming from the on-chip dynamic vision sensor (DVS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynapcnnNetwork(\n",
      "  (sequence): Sequential(\n",
      "    (0): DynapcnnLayer(\n",
      "      (conv_layer): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (spk_layer): IAFSqueeze-module, backend: sinabs\n",
      "      (pool_layer): SumPool2d(norm_type=1, kernel_size=(2, 2), stride=None, ceil_mode=False)\n",
      "    )\n",
      "    (1): DynapcnnLayer(\n",
      "      (conv_layer): Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (spk_layer): IAFSqueeze-module, backend: sinabs\n",
      "      (pool_layer): SumPool2d(norm_type=1, kernel_size=(2, 2), stride=None, ceil_mode=False)\n",
      "    )\n",
      "    (2): DynapcnnLayer(\n",
      "      (conv_layer): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (spk_layer): IAFSqueeze-module, backend: sinabs\n",
      "      (pool_layer): SumPool2d(norm_type=1, kernel_size=(2, 2), stride=None, ceil_mode=False)\n",
      "    )\n",
      "    (3): DynapcnnLayer(\n",
      "      (conv_layer): Conv2d(128, 500, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (spk_layer): IAFSqueeze-module, backend: sinabs\n",
      "    )\n",
      "    (4): DynapcnnLayer(\n",
      "      (conv_layer): Conv2d(500, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (spk_layer): IAFSqueeze-module, backend: sinabs\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# - Input dimensions\n",
    "input_shape = (1, 28, 28)\n",
    "\n",
    "# - DYNAP-CNN compatible network\n",
    "dynapcnn_net = DynapcnnNetwork(\n",
    "    sinabs_model.spiking_model,\n",
    "    input_shape=input_shape,\n",
    "    discretize=True,\n",
    "    dvs_input=False,\n",
    ")\n",
    "print(dynapcnn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting model consists of 5 `DynapcnnLayer` objects, each containing a convolutional, a spiking, and possibly a pooling layer. Because there were 5 parameter layers (as we pointed out earlier), each gets mapped into a separate layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Lets pass some data and see how this converted spiking model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset for spiking input data\n",
    "class MNIST_Dataset(datasets.MNIST):\n",
    "\n",
    "    def __init__(self, root, train = True, spiking=False, tWindow=100):\n",
    "        super().__init__(root, train=train, download=True)\n",
    "        self.spiking=spiking\n",
    "        self.tWindow = tWindow\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.spiking:\n",
    "            img = (np.random.rand(self.tWindow, 1, *img.size()) < img.numpy()/255.0).astype(float)\n",
    "            img = torch.from_numpy(img).float()\n",
    "        else:\n",
    "            # Convert image to tensor\n",
    "            img = torch.from_numpy(img.numpy()).float()\n",
    "            img.unsqueeze_(0)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Define dataloader\n",
    "tWindow = 200 # ms (or) time steps\n",
    "\n",
    "# Define test dataset\n",
    "test_dataset = MNIST_Dataset(\"./data\", train=False, spiking=True, tWindow=tWindow)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6064079b7b1046bfa3a88da22549931c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data, label \u001B[38;5;129;01min\u001B[39;00m pbar:\n\u001B[1;32m      7\u001B[0m     dynapcnn_net\u001B[38;5;241m.\u001B[39mreset_states()\n\u001B[0;32m----> 8\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mdynapcnn_net\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Calculate total number of spikes out\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     pred \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/backend/dynapcnn/dynapcnn_network.py:336\u001B[0m, in \u001B[0;36mDynapcnnNetwork.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    335\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 141\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/backend/dynapcnn/dynapcnn_layer.py:278\u001B[0m, in \u001B[0;36mDynapcnnLayer.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03m\"\"\"Torch forward pass.\"\"\"\u001B[39;00m\n\u001B[1;32m    277\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_layer(x)\n\u001B[0;32m--> 278\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspk_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool_layer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    280\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool_layer(x)\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/layers/iaf.py:164\u001B[0m, in \u001B[0;36mIAFSqueeze.forward\u001B[0;34m(self, input_data)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_data: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/layers/squeeze_layer.py:20\u001B[0m, in \u001B[0;36mSqueezeMixin.squeeze_forward\u001B[0;34m(self, input_data, forward_method)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msqueeze_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_data: torch\u001B[38;5;241m.\u001B[39mTensor, forward_method: Callable):\n\u001B[1;32m     17\u001B[0m     inflated_input \u001B[38;5;241m=\u001B[39m input_data\u001B[38;5;241m.\u001B[39mreshape(\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps, \u001B[38;5;241m*\u001B[39minput_data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m     19\u001B[0m     )\n\u001B[0;32m---> 20\u001B[0m     inflated_output \u001B[38;5;241m=\u001B[39m \u001B[43mforward_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43minflated_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inflated_output\u001B[38;5;241m.\u001B[39mflatten(start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, end_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/layers/iaf.py:57\u001B[0m, in \u001B[0;36mIAF.forward\u001B[0;34m(self, input_data)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_state_initialised() \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_has_shape(\n\u001B[1;32m     53\u001B[0m     (batch_size, \u001B[38;5;241m*\u001B[39mtrailing_dim)\n\u001B[1;32m     54\u001B[0m ):\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_state_with_shape((batch_size, \u001B[38;5;241m*\u001B[39mtrailing_dim))\n\u001B[0;32m---> 57\u001B[0m spikes, state \u001B[38;5;241m=\u001B[39m \u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlif_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha_mem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha_syn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnamed_buffers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[43m    \u001B[49m\u001B[43mactivation_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreshold_low\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthreshold_low\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnorm_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_mem \u001B[38;5;241m=\u001B[39m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv_mem\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfiring_rate \u001B[38;5;241m=\u001B[39m spikes\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m/\u001B[39m spikes\u001B[38;5;241m.\u001B[39mnumel()\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/layers/functional/lif.py:48\u001B[0m, in \u001B[0;36mlif_forward\u001B[0;34m(input_data, alpha_mem, alpha_syn, state, activation_fn, threshold_low, norm_input)\u001B[0m\n\u001B[1;32m     46\u001B[0m output_spikes \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_time_steps):\n\u001B[0;32m---> 48\u001B[0m     spikes, state \u001B[38;5;241m=\u001B[39m \u001B[43mlif_forward_single\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha_mem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha_mem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha_syn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha_syn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivation_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivation_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthreshold_low\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthreshold_low\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnorm_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     output_spikes\u001B[38;5;241m.\u001B[39mappend(spikes)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mstack(output_spikes, \u001B[38;5;241m1\u001B[39m), state\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/layers/functional/lif.py:26\u001B[0m, in \u001B[0;36mlif_forward_single\u001B[0;34m(input_data, alpha_mem, alpha_syn, state, activation_fn, threshold_low, norm_input)\u001B[0m\n\u001B[1;32m     23\u001B[0m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv_mem\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m alpha_mem \u001B[38;5;241m*\u001B[39m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv_mem\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi_syn\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# generate spikes and adjust v_mem\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m spikes, state \u001B[38;5;241m=\u001B[39m \u001B[43mactivation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m threshold_low \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     29\u001B[0m     state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv_mem\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     30\u001B[0m             torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mrelu(state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv_mem\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m-\u001B[39m threshold_low) \u001B[38;5;241m+\u001B[39m threshold_low\n\u001B[1;32m     31\u001B[0m     )\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/activation/activation.py:43\u001B[0m, in \u001B[0;36mActivationFunction.__call__\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m\"\"\"Takes in neuron states and returns a tuple of (spikes, new states).\"\"\"\u001B[39;00m\n\u001B[1;32m     42\u001B[0m input_tensors \u001B[38;5;241m=\u001B[39m [state[name] \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspike_fn\u001B[38;5;241m.\u001B[39mrequired_states]\n\u001B[0;32m---> 43\u001B[0m spikes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspike_fn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspike_threshold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msurrogate_grad_fn\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_fn(spikes, state, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspike_threshold)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m spikes, state\n",
      "File \u001B[0;32m~/Work/git/sinabs-dynapcnn/venv/lib/python3.9/site-packages/sinabs/activation/spike_generation.py:38\u001B[0m, in \u001B[0;36mMultiSpike.forward\u001B[0;34m(ctx, v_mem, threshold, surrogate_grad_fn)\u001B[0m\n\u001B[1;32m     36\u001B[0m ctx\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m threshold\n\u001B[1;32m     37\u001B[0m ctx\u001B[38;5;241m.\u001B[39msurrogate_grad_fn \u001B[38;5;241m=\u001B[39m surrogate_grad_fn\n\u001B[0;32m---> 38\u001B[0m spikes \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mv_mem\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdiv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mv_mem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrounding_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrunc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     40\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m spikes\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = 0\n",
    "    # we will only use the first 500 samples to save some time\n",
    "    pbar = tqdm(test_dataset, total=500)\n",
    "    for data, label in pbar:\n",
    "        dynapcnn_net.reset_states()\n",
    "        out = dynapcnn_net(data)\n",
    "\n",
    "        # Calculate total number of spikes out\n",
    "        pred = out.squeeze().sum(0)\n",
    "        \n",
    "        # Check if the prediction matches the label\n",
    "        if pred.argmax() == label:\n",
    "            correct += 1\n",
    "        samples += 1\n",
    "        pbar.set_postfix(acc=100*correct/samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy of this model can now be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Accuracy of the  dynapcnn_net is: {100*correct/samples}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porting model to DYNAP-CNN DevKit\n",
    "\n",
    "Similar to porting a model to `cpu` or `gpu` in pytorch, the `DynapcnnNetwork` is a special class that supports porting a model to hardware based on DYNAP-CNN technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model to device such as dynapcnndevkit, speck2, speck2b\n",
    "device = \"speck2b\"\n",
    "dynapcnn_net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can findout where the individual layers have been placed on the chip by looking at variable `chip_layers_ordering`. This information will come in handy when trying to send or receive events from the chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dynapcnn_net.chip_layers_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model described above, we were able to find a sequence of layers on the chip which could be utilized. If we had a larger model that does not fit the chip, the `to` method call would have raised a `ValueError`. In that case, it would be handy to understand the model's memory requirements so that it can be modified to fit the chip. A quick overview of the memory requirements of the model can be found by calling the method `memory_summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynapcnn_net.memory_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that this memory is not the same as the total number of kernel parameters. See the `memory_summary` documentation for more details on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `memory_summary()` method returns the number of parameters/memory required for each layer of the  `DynapcnnNetwork` for kernel, neruons and bias. We see the corresponding values for the 5 layers of our current model above.\n",
    "\n",
    "You can compare these values to the `constrains` of the chip. For instance, the chip constraints for your device can be viewed from `DynapcnnConfigBuilder.get_constriants()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = ChipFactory(device).get_config_builder()\n",
    "builder.get_constraints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending a receiving spikes\n",
    "\n",
    "Last but not least, we want to be able to send and receive spikes from the chips.\n",
    "\n",
    "So first we start by generating some spike events. Unlike simulations where the spikes were presented as a `tensor` (a raster of spikes), for the chip, we will send a sequence of custom event objects. We can convert a spike raster `tensor` to a list of events using the utility funciton `ChipFactory.raster_to_events()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster, label = test_dataset[0]\n",
    "\n",
    "factory = ChipFactory(device)\n",
    "first_layer_idx = dynapcnn_net.chip_layers_ordering[0] \n",
    "events_in = factory.raster_to_events(raster, layer=first_layer_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these events can be sent to the chip. You can do this similarly to what you would do for a `pytorch` model on GPU or CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_out = dynapcnn_net(events_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We receive spike objects from the hardware as output. We expect them to be from the last layer of the model (chip_layers_ordering[-1]) and for the data we sent in, we expect most spikes to be from the neuron index equal to label. Let's convert those to a tensor/raster format for easy slicing. Since the last layer has dimensions (10, 1, 1) for (feature, y, x), we are interested in the feature value of the neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = factory.events_to_raster(events_out)\n",
    "output.sum([0,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that neuron 7 produced most spikes. Lets see what the original label of our data was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! Success. Our model on the chip identified the input data correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}